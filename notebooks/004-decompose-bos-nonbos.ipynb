{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gross code to allow for importing from parent directory\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(os.getcwd()).parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "import gc\n",
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "from load_data import get_prompts_t\n",
    "from plotting import ntensor_to_long\n",
    "from jamesd_utils import reinforcement_ratio, projection_value\n",
    "\n",
    "from plotly.graph_objs.layout._shape import Shape\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "\n",
    "# Global settings and variables\n",
    "torch.set_grad_enabled(False)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 80 prompts from c4-tokenized-2b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c54e1b47d242c199441f6264013ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 prompts from code-tokenized...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8bbf17b1e74d46a6ffb64c584f1958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts = get_prompts_t()\n",
    "# prompts = get_prompts_t(n_text_prompts=160, n_code_prompts=40)\n",
    "\n",
    "# Throws a warning if there is a non-unique prompt\n",
    "if not (torch.unique(prompts, dim=0).shape == prompts.shape):\n",
    "    print(\"WARNING: at least 1 prompt is not unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-4l into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "#Transformer Lens model names:\n",
    "# https://github.com/neelnanda-io/TransformerLens/blob/3cd943628b5c415585c8ef100f65989f6adc7f75/transformer_lens/loading_from_pretrained.py#L127\n",
    "\n",
    "model_name = \"gelu-4l\"\n",
    "model = HookedTransformer.from_pretrained(model_name, device=device)\n",
    "model.cfg.use_attn_result = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hook points to cache\n",
    "hook_names = [\n",
    "    \"blocks.0.attn.hook_pattern\",\n",
    "    \"blocks.0.attn.hook_v\",\n",
    "    \"blocks.0.attn.hook_z\",\n",
    "    \"blocks.0.attn.hook_result\",\n",
    "    \"blocks.2.attn.hook_result\",\n",
    "]\n",
    "\n",
    "# Run a forward pass and cache selected activations\n",
    "_, cache = model.run_with_cache(\n",
    "    prompts[:30],\n",
    "    names_filter=lambda name: name in hook_names,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Delete logits and garbage collect\n",
    "del _\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 8, 1024, 1024])\n",
      "torch.Size([30, 1024, 8, 64])\n",
      "torch.Size([30, 1024, 8, 64])\n"
     ]
    }
   ],
   "source": [
    "print(cache[\"blocks.0.attn.hook_pattern\"].shape)  # (batch, head, posQ, posK)\n",
    "print(cache[\"blocks.0.attn.hook_v\"].shape)  # (batch, pos, head, d_head)\n",
    "print(cache[\"blocks.0.attn.hook_z\"].shape)  # (batch, pos, head, d_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check calculation of `z` from `pattern` and `v` for H0.2\n",
    "pattern_from_cache = cache[\"blocks.0.attn.hook_pattern\"][:, 2, :, :]\n",
    "v_from_cache = cache[\"blocks.0.attn.hook_v\"][:, :, 2, :]\n",
    "z_from_cache = cache[\"blocks.0.attn.hook_z\"][:, :, 2, :]\n",
    "\n",
    "z = einops.einsum(\n",
    "    pattern_from_cache,  # (batch posQ posK)\n",
    "    v_from_cache,  # (batch pos d_head)\n",
    "    \"batch posQ posK, batch posK d_head -> batch posQ d_head\",\n",
    ")\n",
    "assert torch.allclose(z, z_from_cache, atol=1e-5)\n",
    "\n",
    "# Double check calculation of `result` from `z` and `W_O` for H0.2\n",
    "W_O_H0_2 = model.W_O[0, 2]  # (d_head, d_model)\n",
    "result_from_cache = cache[\"blocks.0.attn.hook_result\"][:, :, 2, :]  # (batch, pos, d_model)\n",
    "\n",
    "result = einops.einsum(\n",
    "    z_from_cache,\n",
    "    W_O_H0_2,\n",
    "    \"batch pos d_head, d_head d_model -> batch pos d_model\",\n",
    ")\n",
    "assert torch.allclose(result, result_from_cache, atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposing BOS and non-BOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 1024, 1])\n",
      "torch.Size([30, 1024, 1023])\n",
      "torch.Size([30, 1, 64])\n",
      "torch.Size([30, 1023, 64])\n"
     ]
    }
   ],
   "source": [
    "# Slice BOS and non-BOS vectors for H0.2\n",
    "pattern_bos = cache[\"blocks.0.attn.hook_pattern\"][:, 2, :, 0:1]  # slice BOS but keep dim\n",
    "pattern_nonbos = cache[\"blocks.0.attn.hook_pattern\"][:, 2, :, 1:]\n",
    "v_bos = cache[\"blocks.0.attn.hook_v\"][:, 0:1, 2, :]\n",
    "v_nonbos = cache[\"blocks.0.attn.hook_v\"][:, 1:, 2, :]\n",
    "\n",
    "print(pattern_bos.shape)\n",
    "print(pattern_nonbos.shape)\n",
    "print(v_bos.shape)\n",
    "print(v_nonbos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate decomposed zs\n",
    "z_bos = einops.einsum(\n",
    "    pattern_bos,  # (batch posQ posK)\n",
    "    v_bos,  # (batch pos d_head)\n",
    "    \"batch posQ posK, batch posK d_head -> batch posQ d_head\",\n",
    ")\n",
    "z_nonbos = einops.einsum(\n",
    "    pattern_nonbos,  # (batch posQ posK)\n",
    "    v_nonbos,  # (batch pos d_head)\n",
    "    \"batch posQ posK, batch posK d_head -> batch posQ d_head\",\n",
    ")\n",
    "\n",
    "# Final z shapes should match\n",
    "assert z_bos.shape == z_nonbos.shape\n",
    "\n",
    "# Calculate decomposed results from decomposed zs\n",
    "result_bos = einops.einsum(\n",
    "    z_bos,\n",
    "    W_O_H0_2,\n",
    "    \"batch pos d_head, d_head d_model -> batch pos d_model\",\n",
    ")\n",
    "result_nonbos = einops.einsum(\n",
    "    z_nonbos,\n",
    "    W_O_H0_2,\n",
    "    \"batch pos d_head, d_head d_model -> batch pos d_model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projecting H2.X onto H0.2_BOS and H0.2_nonBOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 1024, 512])\n",
      "torch.Size([1, 30, 1024, 512])\n",
      "torch.Size([8, 30, 1024, 512])\n"
     ]
    }
   ],
   "source": [
    "# Get and rearrange vectors to project from and onto\n",
    "result_H0_2_bos = einops.rearrange(result_bos, \"batch pos d_model -> 1 batch pos d_model\")\n",
    "result_H0_2_nonbos = einops.rearrange(result_nonbos, \"batch pos d_model -> 1 batch pos d_model\")\n",
    "results_H2_X = einops.rearrange(\n",
    "    cache[\"blocks.2.attn.hook_result\"], \"batch pos head d_model -> head batch pos d_model\"\n",
    ")\n",
    "\n",
    "# All shapes: (head, batch, pos, d_model)\n",
    "print(result_H0_2_bos.shape)\n",
    "print(result_H0_2_nonbos.shape)\n",
    "print(results_H2_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BOS dataframe with RRs and PVs\n",
    "df_bos = ntensor_to_long(\n",
    "    reinforcement_ratio(results_H2_X, result_H0_2_bos),\n",
    "    value_name=\"reinforcement_ratio\",\n",
    "    dim_names=[\"L2_head\", \"batch\", \"pos\"]\n",
    ")\n",
    "df_bos[\"projection_value\"] = projection_value(results_H2_X, result_H0_2_bos).flatten().cpu().numpy()\n",
    "df_bos[\"decomposition\"] = \"BOS-only\"\n",
    "df_bos[\"decomposition\"] = df_bos[\"decomposition\"].astype(\"category\")\n",
    "\n",
    "# Create non-BOS dataframe with RRs and PVs\n",
    "df_nonbos = ntensor_to_long(\n",
    "    reinforcement_ratio(results_H2_X, result_H0_2_nonbos),\n",
    "    value_name=\"reinforcement_ratio\",\n",
    "    dim_names=[\"L2_head\", \"batch\", \"pos\"]\n",
    ")\n",
    "df_nonbos[\"projection_value\"] = projection_value(results_H2_X, result_H0_2_nonbos).flatten().cpu().numpy()\n",
    "df_nonbos[\"decomposition\"] = \"non-BOS\"\n",
    "df_nonbos[\"decomposition\"] = df_nonbos[\"decomposition\"].astype(\"category\")\n",
    "\n",
    "# Concat BOS and non-BOS dataframes\n",
    "df = pd.concat([df_bos, df_nonbos], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.431808"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df memory usage in MB\n",
    "df.memory_usage(deep=True).sum() / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 491520 entries, 0 to 491519\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   reinforcement_ratio  491280 non-null  float32\n",
      " 1   L2_head              491520 non-null  int64  \n",
      " 2   batch                491520 non-null  int64  \n",
      " 3   pos                  491520 non-null  int64  \n",
      " 4   projection_value     491280 non-null  float32\n",
      " 5   decomposition        491520 non-null  object \n",
      "dtypes: float32(2), int64(3), object(1)\n",
      "memory usage: 18.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reinforcement_ratio</th>\n",
       "      <th>L2_head</th>\n",
       "      <th>batch</th>\n",
       "      <th>pos</th>\n",
       "      <th>projection_value</th>\n",
       "      <th>decomposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.007003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.033858</td>\n",
       "      <td>BOS-only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.004715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.020793</td>\n",
       "      <td>BOS-only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.102663</td>\n",
       "      <td>BOS-only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.006347</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.026894</td>\n",
       "      <td>BOS-only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.032231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.131472</td>\n",
       "      <td>BOS-only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491515</th>\n",
       "      <td>-0.180769</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>1019</td>\n",
       "      <td>-1.079486</td>\n",
       "      <td>non-BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491516</th>\n",
       "      <td>-0.157808</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>1020</td>\n",
       "      <td>-0.949479</td>\n",
       "      <td>non-BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491517</th>\n",
       "      <td>-0.168287</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>1021</td>\n",
       "      <td>-1.054651</td>\n",
       "      <td>non-BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491518</th>\n",
       "      <td>-0.106527</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>1022</td>\n",
       "      <td>-0.626664</td>\n",
       "      <td>non-BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491519</th>\n",
       "      <td>-0.092576</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>1023</td>\n",
       "      <td>-0.551685</td>\n",
       "      <td>non-BOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>491520 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        reinforcement_ratio  L2_head  batch   pos  projection_value  \\\n",
       "0                 -0.007003        0      0     0         -0.033858   \n",
       "1                 -0.004715        0      0     1         -0.020793   \n",
       "2                  0.024795        0      0     2          0.102663   \n",
       "3                 -0.006347        0      0     3         -0.026894   \n",
       "4                  0.032231        0      0     4          0.131472   \n",
       "...                     ...      ...    ...   ...               ...   \n",
       "491515            -0.180769        7     29  1019         -1.079486   \n",
       "491516            -0.157808        7     29  1020         -0.949479   \n",
       "491517            -0.168287        7     29  1021         -1.054651   \n",
       "491518            -0.106527        7     29  1022         -0.626664   \n",
       "491519            -0.092576        7     29  1023         -0.551685   \n",
       "\n",
       "       decomposition  \n",
       "0           BOS-only  \n",
       "1           BOS-only  \n",
       "2           BOS-only  \n",
       "3           BOS-only  \n",
       "4           BOS-only  \n",
       "...              ...  \n",
       "491515       non-BOS  \n",
       "491516       non-BOS  \n",
       "491517       non-BOS  \n",
       "491518       non-BOS  \n",
       "491519       non-BOS  \n",
       "\n",
       "[491520 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
